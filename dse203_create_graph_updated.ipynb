{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import pakages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import json\n",
    "import neo4j\n",
    "import py2neo\n",
    "from pprint import pprint\n",
    "\n",
    "from py2neo import Database\n",
    "from py2neo import Graph, Node, Relationship, NodeMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connet neo4j database. \n",
    "HOST='localhost'\n",
    "# USER='neo4jproj'# Set your own username.\n",
    "USER='neo4j'\n",
    "PW='1234' # Set your own password."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val(data:dict,key:str) -> str:\n",
    "    \n",
    "    ''' Get values from dictionary, \n",
    "        if key not in dictionary return None '''\n",
    "        \n",
    "    if key == 'Founder':\n",
    "        if key not in data.keys():\n",
    "            new_key='Founder(s)'\n",
    "            if new_key not in data.keys():\n",
    "                return None \n",
    "            else:\n",
    "                return data[new_key]\n",
    "        \n",
    "    elif key not in data.keys():\n",
    "        return None\n",
    "        \n",
    "    elif data[key]=='':\n",
    "        return None\n",
    "    \n",
    "    else:\n",
    "        return data[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acquisition for all companies.\n",
    "\n",
    "Created a csv file with company acquisition, year and amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictiionary for acquisition. {company:{acquired_company:[year, amount]}...}\n",
    "acquisition={}\n",
    "with open('./info_box/Acquisition.csv') as Acquisition:\n",
    "    acquisition_all = csv.DictReader(Acquisition)\n",
    "    for row in acquisition_all:\n",
    "        if row['Company'] in acquisition.keys():\n",
    "            acquisition[row['Company']][row['Acquisition']]= [get_val(row,'Year'),get_val(row,'Amount')]\n",
    "        else:\n",
    "            acquisition[row['Company']]={}\n",
    "            acquisition[row['Company']][row['Acquisition']] = [get_val(row,'Year'),get_val(row,'Amount')]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Alibaba': {'Alibaba Pictures': ['2014', ' $805 million'],\n",
      "             'Amblin Partners': ['2016', None],\n",
      "             'Ant Financial': ['2014', None],\n",
      "             'South China Morning Post': ['2015', '$266 million '],\n",
      "             'Vendio': ['2010', None]},\n",
      " 'Amazon': {'Ring Inc.': ['2018', '$1000 million'],\n",
      "            'Whole Foods Market': ['2017', '$13700 million'],\n",
      "            'Zappos': ['2009', '$1200 million ']},\n",
      " 'Walmart': {'Jet.com': ['2016', '$3000 million'],\n",
      "             'Shoes.com': ['1993', '$70 million'],\n",
      "             'Vudu': ['2010', '$100 million']},\n",
      " 'eBay': {'Craigslist': ['2004', '$13.5 million'],\n",
      "          'PayPal': ['2002', '$1500 million'],\n",
      "          'Skype Technologies': ['2005', '$2600 million']}}\n"
     ]
    }
   ],
   "source": [
    "pprint(acquisition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAICS Code: Create company_naics_code dictionary.\n",
    "\n",
    "Note: Add company name to the company list in \"scrape_naics.py\".\n",
    "\n",
    "- Youtube ==> Youku \"can not find company\" ;\n",
    "\n",
    "- Paramount Pictures ==> Alibaba Pictures \"can not find company\" \n",
    "\n",
    "company_list = ['Alibaba', 'Walmart', 'eBay', 'Amazon','Youtube','Paramount Pictures','Costco','Kroger','Target','Vudu','Jet.com','Kmart']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique naics codes.\n",
    "naics=dict() \n",
    "# Company and 6 digits Naics Code, which we need create relation between code and company. \n",
    "company_code=dict() \n",
    "\n",
    "with open('./naics_scraped_all.csv') as file:\n",
    "    data = csv.DictReader(file)\n",
    "    for row in data:\n",
    "        company = row['Company']\n",
    "        code = row['NAICS_CODE']\n",
    "        title = row['NAICS_TITLE']\n",
    "        naics[code] = title\n",
    "        if company not in company_code.keys():\n",
    "             company_code[company]=code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Alibaba': '561990',\n",
       " 'Amazon': '443142',\n",
       " 'Amblin': '334513',\n",
       " 'Craigslist': '541860',\n",
       " 'Evening Post': '512191',\n",
       " 'Jet.com': '237990',\n",
       " 'Paramount Pictures': '512191',\n",
       " 'PayPal': '551112',\n",
       " 'Ring': '336412',\n",
       " 'Shoebuy.com': '454110',\n",
       " 'Skype Technologies': '611310',\n",
       " 'Vendio': '442110',\n",
       " 'Vudu': '518210',\n",
       " 'Walmart': '445110',\n",
       " 'Whole Foods Market': '722310',\n",
       " 'Zappos': '448210',\n",
       " 'eBay': '561990'}"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change company names:\n",
    "## 'Paramount Pictures' -> 'Alibaba Pictures'\n",
    "## 'Ring' -> 'Ring Inc.' (Change to full name)\n",
    "## 'Amblin' -> 'Amblin Partners' (Change to full name)\n",
    "## 'Shoebuy.com' -> 'Shoes.com' (Shoebuy.com is former name)\n",
    "## 'Evening Post' -> 'South China Morning Post'\n",
    "\n",
    "company_code['Alibaba Pictures'] = company_code['Paramount Pictures']\n",
    "company_code['Ring Inc.'] = company_code['Ring']\n",
    "company_code['Amblin Partners'] = company_code['Amblin']\n",
    "company_code['Shoes.com'] = company_code['Shoebuy.com']\n",
    "company_code['South China Morning Post'] = company_code['Evening Post']\n",
    "\n",
    "del company_code['Paramount Pictures']\n",
    "del company_code['Ring']\n",
    "del company_code['Amblin']\n",
    "del company_code['Shoebuy.com']\n",
    "del company_code['Evening Post']\n",
    "\n",
    "# Add code for \"Ant Financial\"; use same code as PayPal\n",
    "company_code.update( {'Ant Financial' : company_code['PayPal'] } )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique root code.\n",
    "root_code = [code for code in naics.keys() if len(code)==2 or re.match('\\d+-\\d+',code)]\n",
    "\n",
    "# Code with 6 digits.\n",
    "code6 = [code for code in naics.keys() if len(code)==6]\n",
    "# Code with 5 digits.\n",
    "code5 = [code for code in naics.keys() if len(code)==5 and not re.match('\\d+-\\d+',code)]\n",
    "# Code with 4 digits.\n",
    "code4 = [code for code in naics.keys() if len(code)==4]\n",
    "# Code with 3 digits.\n",
    "code3 = [code for code in naics.keys() if len(code)==3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['55', '31-33', '61', '72', '56', '54', '44-45', '23', '51']\n",
      "['611', '237', '541', '722', '518', '448', '454', '336', '445', '443', '334', '442', '512', '561', '551']\n",
      "['4451', '2379', '4421', '3364', '5182', '5619', '4482', '7223', '5418', '5511', '3345', '6113', '4541', '4431', '5121']\n",
      "['55111', '72231', '56199', '51821', '54186', '45411', '61131', '44211', '44314', '33451', '44511', '23799', '51219', '33641', '44821']\n",
      "['443142', '336412', '237990', '722310', '561990', '551112', '512191', '454110', '445110', '334513', '448210', '442110', '611310', '541860', '518210'] \n",
      "\n",
      "{'Alibaba': '561990',\n",
      " 'Alibaba Pictures': '512191',\n",
      " 'Amazon': '443142',\n",
      " 'Amblin Partners': '334513',\n",
      " 'Ant Financial': '551112',\n",
      " 'Craigslist': '541860',\n",
      " 'Jet.com': '237990',\n",
      " 'PayPal': '551112',\n",
      " 'Ring Inc.': '336412',\n",
      " 'Shoes.com': '454110',\n",
      " 'Skype Technologies': '611310',\n",
      " 'South China Morning Post': '512191',\n",
      " 'Vendio': '442110',\n",
      " 'Vudu': '518210',\n",
      " 'Walmart': '445110',\n",
      " 'Whole Foods Market': '722310',\n",
      " 'Zappos': '448210',\n",
      " 'eBay': '561990'}\n"
     ]
    }
   ],
   "source": [
    "print(root_code)\n",
    "print(code3)\n",
    "print(code4)\n",
    "print(code5)\n",
    "print(code6,'\\n')\n",
    "pprint(company_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create graph. \n",
    "### Company Nodes and relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE** : I used the script in `'./scrapy_spider/scrapy_spider/spiders/wiki_spider_info.py'` to extracted the info box and saved in `info_box` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_Company_Node(json):\n",
    "    \n",
    "    '''Create company node'''\n",
    "    revenue = get_val(json,'Revenue')\n",
    "    employee = get_val(json,'Number of employees')\n",
    "    if not employee:\n",
    "        employee = get_val(json, 'Employees')\n",
    "        if employee:\n",
    "            employee =employee.replace(\"c.\", '')\n",
    "    founded = get_val(json,'Founded')\n",
    "    revenue_num = None\n",
    "    employee_num = None\n",
    "    founded_yr = None\n",
    "    \n",
    "    if revenue:\n",
    "        revenue = revenue.lower()\n",
    "        r_has_billion = 'billion' in revenue\n",
    "        r_has_million = 'million' in revenue\n",
    "        \n",
    "        revenue_num = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", revenue)\n",
    "        revenue_num = float(re.sub(\"[^0-9\\.]\", \"\", revenue_num))\n",
    "        if r_has_billion:\n",
    "            revenue_num = revenue_num * 1000000000\n",
    "        elif r_has_million:\n",
    "            revenue_num = revenue_num * 1000000\n",
    "\n",
    "    if employee:\n",
    "        employee = employee.lower()\n",
    "        e_has_billion = 'billion' in employee\n",
    "        e_has_million = 'million' in employee\n",
    "        e_worldwide = 'worldwide' in employee\n",
    "        e_has_range = '–' in employee\n",
    "        if e_worldwide:\n",
    "            employee = employee.split('worldwide')[0]\n",
    "        if e_has_range:\n",
    "            employee = employee.split('–')[1]\n",
    "        employee_num = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", employee)\n",
    "        employee_num = float(re.sub(\"[^0-9\\.]\", \"\", employee_num))\n",
    "\n",
    "        if e_has_billion:\n",
    "            employee_num = employee_num * 1000000000\n",
    "        elif e_has_million:\n",
    "            employee_num = employee_num * 1000000\n",
    "    \n",
    "    if founded:\n",
    "        founded_yr = re.findall('(\\d{4})', founded)\n",
    "        if founded_yr:\n",
    "            founded_yr = int(founded_yr[0])\n",
    "\n",
    "    company_node = Node('Company', \n",
    "                    name=get_val(json,'Title'),\n",
    "                    organization_name=get_val(json,'Organization_name'),\n",
    "                    Type=get_val(json,'Type'),\n",
    "                    founded=get_val(json,'Founded'),\n",
    "                    founder=get_val(json,'Founder'),\n",
    "                    industry=get_val(json,'Industry'), \n",
    "                    products=get_val(json,'Products'), \n",
    "                    services=get_val(json,'Services'), \n",
    "                    revenue=get_val(json,'Revenue'), \n",
    "                    employees=get_val(json,'Number of employees'),\n",
    "                    parent=get_val(json,'Parent'),\n",
    "                    website=get_val(json,'Website'),\n",
    "                    employee_num=employee_num,\n",
    "                    revenue_num=revenue_num,\n",
    "                       founded_yr=founded_yr)\n",
    "    \n",
    "    company_node.__primarylabel__ = \"Company\"\n",
    "    company_node.__primarykey__ = \"name\"\n",
    "    \n",
    "    return company_node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alibaba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect database.\n",
    "g = Graph(host=HOST,user=USER,password=PW) \n",
    "tx = g.begin()\n",
    "\n",
    "# Main company_Alibaba.\n",
    "with open('./info_box/Alibaba.json') as file:\n",
    "    data = json.load(file)\n",
    "    for d in data:\n",
    "        Alibaba = Create_Company_Node(d)         \n",
    "        tx.create(Alibaba)\n",
    "\n",
    "# Competitor_Alibaba. \n",
    "# ** Please chage the Amazon title in Competitor_Alibaba.json': \"Amazon (Company)\" --> \"Amazon\" ** \n",
    "with open('./info_box/Alibaba_Competitor.json') as file:\n",
    "    data = json.load(file)\n",
    "    for d in data:\n",
    "        company_node = Create_Company_Node(d)\n",
    "        relation = Relationship(Alibaba,'Competitor',company_node)\n",
    "        tx.create(relation)\n",
    "        \n",
    "# Acquisition_Alibaba.\n",
    "with open('./info_box/Alibaba_Acquisition.json') as file:\n",
    "    data = json.load(file)\n",
    "    for d in data:\n",
    "        company_name = d['Title']\n",
    "        company_node = Create_Company_Node(d)\n",
    "        Y = acquisition['Alibaba'][company_name][0]\n",
    "        A = acquisition['Alibaba'][company_name][1]\n",
    "        relation = Relationship(Alibaba,'Acquired',company_node,year=Y,amount=A)\n",
    "        tx.create(relation)        \n",
    "\n",
    "tx.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Walmart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect database.\n",
    "g = Graph(host=HOST,user=USER,password=PW) \n",
    "tx = g.begin()\n",
    "\n",
    "# Find Walmart node.\n",
    "matcher = NodeMatcher(g)\n",
    "Walmart = matcher.match('Company',name='Walmart').first()\n",
    "        \n",
    "# Walmart compete with Amazon and eBay as well.         \n",
    "Amazon = matcher.match('Company',name='Amazon').first()\n",
    "eBay = matcher.match('Company',name='eBay').first()\n",
    "tx.create(Relationship(Amazon,'Competitor',Walmart))\n",
    "tx.create(Relationship(eBay,'Competitor',Walmart))\n",
    "\n",
    "# Acquisition_Walmart. \n",
    "with open('./info_box/Walmart_Acquisition.json') as file:\n",
    "    data = json.load(file)\n",
    "    for d in data:\n",
    "        company_name = d['Title']\n",
    "        company_node = Create_Company_Node(d)\n",
    "        Y = acquisition['Walmart'][company_name][0]\n",
    "        A = acquisition['Walmart'][company_name][1]\n",
    "        relation = Relationship(Walmart,'Acquired',company_node,year=Y,amount=A)\n",
    "        tx.create(relation)\n",
    "        \n",
    "tx.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect database.\n",
    "g = Graph(host=HOST,user=USER,password=PW) \n",
    "tx = g.begin()\n",
    "\n",
    "# Find Walmart node.\n",
    "matcher = NodeMatcher(g)\n",
    "Amazon = matcher.match('Company',name='Amazon').first()\n",
    "        \n",
    "# Amazon Acquisitions. \n",
    "with open('./info_box/Amazon_Acquisition.json') as acquisitions:\n",
    "    data = json.load(acquisitions)\n",
    "    for d in data:\n",
    "        company_name = d['Title']\n",
    "        company_node = Create_Company_Node(d)\n",
    "        Y = acquisition['Amazon'][company_name][0]\n",
    "        A = acquisition['Amazon'][company_name][1]\n",
    "        relation = Relationship(Amazon,'Acquired',company_node,year=Y,amount=A)\n",
    "        tx.create(relation)\n",
    "\n",
    "tx.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### eBay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect database.\n",
    "g = Graph(host=HOST,user=USER,password=PW)\n",
    "tx = g.begin()\n",
    "\n",
    "# Find Walmart node.\n",
    "matcher = NodeMatcher(g)\n",
    "eBay = matcher.match('Company',name='eBay').first()\n",
    "\n",
    "       \n",
    "# Amazon Acquisitions. \n",
    "with open('./info_box/eBay_Acquisition.json') as acquisitions:\n",
    "    data = json.load(acquisitions)\n",
    "    for d in data:\n",
    "        company_name = d['Title']\n",
    "        company_node = Create_Company_Node(d)\n",
    "        Y = acquisition['eBay'][company_name][0]\n",
    "        A = acquisition['eBay'][company_name][1]\n",
    "        relation = Relationship(eBay,'Acquired',company_node,year=Y,amount=A)\n",
    "        tx.create(relation)\n",
    "\n",
    "tx.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add more relationships between companies.\n",
    "# Connect database.\n",
    "g = Graph(host=HOST,user=USER,password=PW)\n",
    "tx = g.begin()\n",
    "\n",
    "matcher = NodeMatcher(g)\n",
    "\n",
    "shoes = matcher.match('Company',name='Shoes.com').first()\n",
    "zappos = matcher.match('Company',name='Zappos').first()\n",
    "tx.create(Relationship(shoes,'Competitor',zappos))\n",
    "\n",
    "pp = matcher.match('Company',name='PayPal').first()\n",
    "af = matcher.match('Company',name='Ant Financial').first()\n",
    "tx.create(Relationship(pp,'Competitor',af))\n",
    "\n",
    "amazon = matcher.match('Company',name='Amazon').first()\n",
    "ebay = matcher.match('Company',name='eBay').first()\n",
    "jet = matcher.match('Company',name='Jet.com').first()\n",
    "tx.create(Relationship(jet,'Competitor',ebay))\n",
    "tx.create(Relationship(jet,'Competitor',amazon))\n",
    "\n",
    "\n",
    "tx.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NAICS code nodes and relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_Code_Node(code):\n",
    "    \n",
    "    '''Create NAICS Ccode node'''\n",
    "    \n",
    "    code_node = Node('NAICS', code=code, title=naics[code])\n",
    "    \n",
    "    code_node.__primarylabel__ = \"NAICS\"\n",
    "    code_node.__primarykey__ = \"code\"\n",
    "    \n",
    "    return code_node\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Check_Code_Node(code):\n",
    "    \n",
    "    '''Check if NAICS Ccode node already exists'''\n",
    "    \n",
    "    node = matcher.match('NAICS', code=code)\n",
    "    \n",
    "    if node == None:\n",
    "        new = Create_Code_Node(code)\n",
    "        return new\n",
    "    else:\n",
    "        return node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Root Code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect database.\n",
    "g = Graph(host=HOST,user=USER,password=PW)\n",
    "tx = g.begin()\n",
    "\n",
    "# Create Root Code Node. (2-digits or d-d)\n",
    "for root in root_code:\n",
    "    root_node = Create_Code_Node(root)\n",
    "    tx.create(root_node)\n",
    "    \n",
    "tx.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-digit-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect database.\n",
    "g = Graph(host=HOST,user=USER,password=PW)\n",
    "tx = g.begin()\n",
    "\n",
    "# Create 3-digit-code Node.\n",
    "matcher = NodeMatcher(g)\n",
    "for code in code3:\n",
    "    node3 = Create_Code_Node(code)\n",
    "    \n",
    "    # Find the root code node.\n",
    "    if code[:-1] in ['44','45']:\n",
    "        node2 = matcher.match('NAICS', code='44-45').first()    \n",
    "    elif code[:-1] in ['31','33']:\n",
    "        node2 = matcher.match('NAICS', code='31-33').first()\n",
    "    else:\n",
    "        node2 = matcher.match('NAICS', code=code[:-1]).first()\n",
    "        \n",
    "    tx.create(Relationship(node3,'SubClassOf',node2))\n",
    "\n",
    "tx.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-digit-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect database\n",
    "g = Graph(host=HOST,user=USER,password=PW)\n",
    "tx = g.begin()\n",
    "\n",
    "# Create 4-digit-code Node.\n",
    "matcher = NodeMatcher(g)\n",
    "for code in code4:\n",
    "    node4 = Create_Code_Node(code)\n",
    "    node3 = matcher.match('NAICS', code=code[:-1]).first()\n",
    "    tx.create(Relationship(node4,'SubClassOf',node3))\n",
    "\n",
    "tx.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-digit-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect database.\n",
    "g = Graph(host=HOST,user=USER,password=PW)\n",
    "tx = g.begin()\n",
    "\n",
    "# Create 5-digit-code Node.\n",
    "matcher = NodeMatcher(g)\n",
    "for code in code5:\n",
    "    node5 = Create_Code_Node(code)\n",
    "    node4 = matcher.match('NAICS', code=code[:-1]).first()\n",
    "    tx.create(Relationship(node5,'SubClassOf',node4))\n",
    "\n",
    "tx.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6-digit-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect database.\n",
    "g = Graph(host=HOST,user=USER,password=PW)\n",
    "tx = g.begin()\n",
    "\n",
    "# Create 5-digit-code Node.\n",
    "matcher = NodeMatcher(g)\n",
    "for code in code6:\n",
    "    node6 = Create_Code_Node(code)\n",
    "    node5 = matcher.match('NAICS', code=code[:-1]).first()\n",
    "    tx.create(Relationship(node6,'SubClassOf',node5))\n",
    "\n",
    "tx.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create relationships between company and 6-digit-code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect database.\n",
    "g = Graph(host=HOST,user=USER,password=PW)\n",
    "tx = g.begin()\n",
    "\n",
    "# Create relationships.\n",
    "matcher = NodeMatcher(g)\n",
    "for company in company_code:\n",
    "    CompanyNode = matcher.match('Company', name=company).first()\n",
    "    CodeNode = matcher.match('NAICS', code=company_code[company]).first()\n",
    "    tx.create(Relationship(CodeNode,'COMPANY',CompanyNode))\n",
    "    \n",
    "tx.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create controversies graph insertion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_Controversy_Node(issue):\n",
    "    \n",
    "    '''Create controversy node'''\n",
    "    \n",
    "    node = Node('Controversy', issue=issue)\n",
    "    \n",
    "    node.__primarylabel__ = \"CONTROVERSY\"\n",
    "    node.__primarykey__ = \"controversy\"\n",
    "    \n",
    "    return node\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Alibaba_Pictures': [], 'Whole Foods Market': ['Re-zoning petition regarding protected wetlands'], 'Amblin Partners': [], 'Walmart': ['2010s crime problem'], 'Ant Financial': [], 'Craigslist': [], 'South China Morning Post': ['Zhao Wei Incident', 'Closure of subsidiary publications', \"Criticism of Xi Jinping's ally withdrawn\", 'Publication of an interview made under duress'], 'PayPal': ['150,000 PayPal cards frozen', 'CFPB consent'], 'Vendio': [], 'Shoes.com': [], 'Amazon': ['Environmental impact', 'Selling counterfeit items', 'Sales and use taxes', 'Income taxes', 'Comments by Donald Trump and Bernie Sanders', 'Working conditions', 'Conflict of interest with the CIA and DOD', 'Seattle head tax and houselessness services', 'Nashville Operations Center of Excellence', 'Facial recognition technology and law enforcement'], 'Jet.com': [], 'eBay': ['2014 security breach'], 'Ring Inc.': [], 'Zappos': [], 'Alibaba': ['Gold Supplier membership', 'Uranium sales', 'Counterfeit items and scams', 'Class action on IPO'], 'Skype Technologies': ['China 2005', 'France 2005', 'United States, CALEA 2006', 'United States, Transparency and PRISM 2013', 'P2P licensing dispute lawsuit and IPO'], 'Vudu': []}\n"
     ]
    }
   ],
   "source": [
    "# table of contents particularly controversies\n",
    "controversy_dict = {}\n",
    "    \n",
    "with open('./table_of_content.txt') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "    #mapping between data from toc and standarize\n",
    "    data['Alibaba'] = data.pop('Alibaba_Group')\n",
    "    data['eBay'] = data.pop('EBay')\n",
    "    data['Amazon'] = data.pop('Amazon_(company)')\n",
    "    data['Amblin Partners'] = data.pop('Amblin_Partners')\n",
    "    data['South China Morning Post'] = data.pop('South_China_Morning_Post')\n",
    "    data['Ant Financial'] = data.pop('Ant_Financial')\n",
    "    data['Ring Inc.'] = data.pop('Ring_Inc.')\n",
    "    data['Whole Foods Market'] = data.pop('Whole_Foods_Market')\n",
    "    data['Skype Technologies'] = data.pop('Skype_Technologies')\n",
    "    \n",
    "    \n",
    "    \n",
    "# company names we entered in neo4j:\n",
    "# Alibaba Pictures, Vendio, Amblin Partners\n",
    "# South China Morning Post, Ant Financial, Ring Inc., Whole Foods Market\n",
    "# Zappos, PayPal, Craigslist, Skype Technologies, Vudu, Jet.com, Shoes.com\n",
    "\n",
    "    for key,val in data.items():\n",
    "        controversy = []\n",
    "        for x in list(val.keys()):\n",
    "            if \"controve\" in x.lower() or \"criticism\" in x.lower() or \"issue\" in x.lower() \\\n",
    "                or \"fraud\" in x.lower() or \"litigation\" in x.lower():\n",
    "                controversy.append(x)\n",
    "        if len(controversy) > 0:\n",
    "            if (len(controversy)> 1):\n",
    "                cfields = []\n",
    "                for x in controversy:\n",
    "                    cfields.append(val[x])\n",
    "                controversy_dict[key] = [item for sublist in cfields for item in sublist] \n",
    "            else: \n",
    "                controversy_field = controversy[0]\n",
    "                controversy_dict[key] = val[controversy_field]\n",
    "        else:\n",
    "            controversy_dict[key] = []\n",
    "        \n",
    "\n",
    "    print(controversy_dict)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect database.\n",
    "g = Graph(host=HOST,user=USER,password=PW)\n",
    "tx = g.begin()\n",
    "\n",
    "# Create relationships.\n",
    "matcher = NodeMatcher(g)\n",
    "for company, controversy_list in controversy_dict.items():\n",
    "    CompanyNode = matcher.match('Company', name=company).first()\n",
    "    for controversy in controversy_list:\n",
    "        controversy_node = Create_Controversy_Node(controversy)\n",
    "        tx.create(Relationship(CompanyNode,'HasControversy',controversy_node ))\n",
    "tx.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add in areas competing in from info box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Node_or_Create(name, primary_label, primary_key, **kwargs):\n",
    "    \n",
    "    '''Create  node'''\n",
    "    node = matcher.match(name, **kwargs).first()\n",
    "\n",
    "    if node == None:\n",
    "        node = Node(name, **kwargs )\n",
    "\n",
    "        node.__primarylabel__ = primary_label\n",
    "        node.__primarykey__ = primary_key\n",
    "\n",
    "        return node\n",
    "    else:\n",
    "        return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Connect database.\n",
    "g = Graph(host=HOST,user=USER,password=PW)\n",
    "\n",
    "\n",
    "#as part of entity resolution, a simple way (no dedupe/nlp library) is to just have a mapping from company \n",
    "#to company as it is currently in neo4j \n",
    "company_mapping = {\n",
    "    \"Alibaba Group\": \"Alibaba\",\n",
    "    \"Amazon (company)\": \"Amazon\",\n",
    "    \"eBay\": \"eBay\",\n",
    "    \"Walmart\": \"Walmart\",\n",
    "    'EBay':'eBay',\n",
    "    'Alibaba Pictures': 'Alibaba Pictures',\n",
    "    'Amblin Partners': 'Amblin Partners',\n",
    "    'South China Morning Post': 'South China Morning Post',\n",
    "    'Ant Financial': 'Ant Financial',\n",
    "    'Ring Inc.': 'Ring Inc.',\n",
    "    'Whole Foods Market': 'Whole Foods Market',\n",
    "    'Skype Technologies': 'Skype Technologies',\n",
    "    'Vendio': 'Vendio',\n",
    "    'Zappos': 'Zappos', \n",
    "    \"PayPal\": \"PayPal\", \n",
    "    \"Craigslist\": \"Craigslist\", \n",
    "    \"Vudu\": \"Vudu\", \n",
    "    \"Jet.com\": \"Jet.com\", \n",
    "    \"Shoes.com\": \"Shoes.com\"\n",
    "}\n",
    "\n",
    "area_competing_in_map = {\n",
    "    \"Walmart\": \"Products\",\n",
    "    \"Amazon\": \"Industry\",\n",
    "    \"Alibaba\": \"Products\",\n",
    "    \"eBay\": \"Services\",\n",
    "    \"Zappos\": \"Industry\",\n",
    "    \"Whole Foods Market\": \"Industry\",\n",
    "    \"Vudu\": \"Services\",\n",
    "    \"Craigslist\": \"Services\",\n",
    "    \"Skype Technologies\": \"Industry\",\n",
    "    \"Jet.com\": \"Type of site\",\n",
    "    \"Shoes.com\": \"Industry\",\n",
    "    \"Alibaba Pictures\": \"Industry\",\n",
    "    \"Vendio\": \"Industry\",\n",
    "}\n",
    "with open('./info_box/all_info_box.json') as all_info_box:\n",
    "    info_box_data = json.load(all_info_box)\n",
    "\n",
    "    for company in info_box_data:\n",
    "        tx = g.begin()\n",
    "        company_title = company['Title'] if company['Title'] != None else company['Organization_name']\n",
    "        company_name = company_mapping[company_title]\n",
    "\n",
    "        area_competing_in_key = area_competing_in_map.get(company_name, None)\n",
    "        if (area_competing_in_key == None):\n",
    "            area_competing_in_key = \"Products\"\n",
    "\n",
    "        areas_competing_in = company.get(area_competing_in_key)\n",
    "        if (areas_competing_in):\n",
    "            CompanyNode = matcher.match('Company', name=company_name).first()\n",
    "            split_companies = areas_competing_in.split(\",\")\n",
    "            if len(split_companies) <2:\n",
    "                split_companies = areas_competing_in.split(\" \")\n",
    "            for area in split_companies:\n",
    "                node = Get_Node_or_Create('Product_Industry_Name', \"PRODUCT_INDUSTRY_NAME\", \"area_name\", product_industry_name=area.strip())\n",
    "                tx.create(Relationship(CompanyNode,'competes_in',node ))\n",
    "            tx.commit()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Add Walmart, Jet.com, Vudu, Shoes.com nlp. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Walmart\n",
    "\n",
    "# Connect database.\n",
    "g = Graph(host=HOST,user=USER,password=PW)\n",
    "tx = g.begin()\n",
    "\n",
    "# Add Walmart nlp.\n",
    "matcher = NodeMatcher(g)\n",
    "walmart=matcher.match('Company',name='Walmart').first()\n",
    "moosejaw=Node('Company',name='Moosejaw')\n",
    "r1=Relationship(walmart,'Acquired',moosejaw, year='2017', amount='$51 million')\n",
    "tx.create(r1)              \n",
    "\n",
    "#Add Attribute to Walmart.\n",
    "with open('./clean_nlp/clean_Walmart.json') as file:\n",
    "    data = json.load(file)\n",
    "    for d in data:\n",
    "        if d['Edge']['Label']=='is':\n",
    "            Attribute=list(d['Node2'].keys())[0]\n",
    "            Property=list(d['Node2'].values())[0]\n",
    "            tx.merge(walmart)\n",
    "            walmart[Attribute] = Property\n",
    "            tx.push(walmart)\n",
    "\n",
    "tx.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Jet.com\n",
    "\n",
    "# Connect database.\n",
    "g = Graph(host=HOST,user=USER,password=PW)\n",
    "tx = g.begin()\n",
    "\n",
    "# Add Jet.com nlp.\n",
    "matcher = NodeMatcher(g)\n",
    "jet=matcher.match('Company',name='Jet.com').first()\n",
    "amazon=matcher.match('Company',name='Amazon').first()\n",
    "person=Node('Person',name='Marc Lore')\n",
    "diapers=Node('Company',name='Diapers.com')\n",
    "r1=Relationship(person,'Sold',diapers,year='November,2010')\n",
    "tx.create(r1)\n",
    "r2=Relationship(person,'coFounded',jet)\n",
    "tx.create(r2)\n",
    "r3=Relationship(amazon,'Acquired',diapers,year='November,2010')\n",
    "tx.create(r3)\n",
    "\n",
    "# Add Attribute to Jet.com\n",
    "with open('./clean_nlp/clean_Jet.com.json') as file:\n",
    "    data = json.load(file)\n",
    "    for d in data:\n",
    "        if d['Edge']['Label']=='is':\n",
    "            Attribute=list(d['Node2'].keys())[0]\n",
    "            Property=list(d['Node2'].values())[0]\n",
    "            tx.merge(jet)\n",
    "            jet[Attribute] = Property\n",
    "            tx.push(jet)\n",
    "               \n",
    "tx.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Shoes.com\n",
    "\n",
    "# Connect database.\n",
    "graph = Graph(host=HOST,user=USER,password=PW)\n",
    "tx = graph.begin()\n",
    "\n",
    "# Find Shoes.com node.\n",
    "matcher = NodeMatcher(g)\n",
    "shoe=matcher.match('Company',name='Shoes.com').first()\n",
    "\n",
    "# Add Attribute to Shoes.com\n",
    "with open('./clean_nlp/clean_Shoes.com.json') as file:\n",
    "    data = json.load(file)\n",
    "    for d in data:\n",
    "        if d['Edge']['Label']=='is':\n",
    "            Attribute=list(d['Node2'].keys())[0]\n",
    "            Property=list(d['Node2'].values())[0]\n",
    "            tx.merge(shoe)\n",
    "            shoe[Attribute] = Property\n",
    "            tx.push(shoe)\n",
    "               \n",
    "tx.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Vudu\n",
    "          \n",
    "# Connect database.\n",
    "g = Graph(host=HOST,user=USER,password=PW)\n",
    "tx = g.begin()\n",
    "\n",
    "\n",
    "# Find Vudu node.\n",
    "matcher = NodeMatcher(g)\n",
    "vudu=matcher.match('Company',name='Vudu').first()\n",
    "\n",
    "# Add Attribute to Vudu.\n",
    "with open('./clean_nlp/clean_Vudu.json') as file:\n",
    "    data = json.load(file)\n",
    "    for d in data:\n",
    "        if d['Edge']['Label']=='is':\n",
    "            Attribute=list(d['Node2'].keys())[0]\n",
    "            Property=list(d['Node2'].values())[0]\n",
    "            tx.merge(vudu)\n",
    "            vudu[Attribute] = Property\n",
    "            tx.push(vudu)\n",
    "               \n",
    "tx.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Adding Alibaba and affiliate (Amblin Partners, Ant Financial, South China Morning Post)\n",
    "#### Uses 3 separate csvs to model nodes, node attributes, and relationships between nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add nodes \n",
    "g = Graph(host=HOST,user=USER,password=PW)\n",
    "tx = g.begin()\n",
    "\n",
    "with open('./clean_nlp/node_labels.csv','rt')as f:\n",
    "    node_labels = csv.reader(f)\n",
    "    for row in node_labels:\n",
    "        \n",
    "        name = row[0]\n",
    "        node_type = row[1]\n",
    "        \n",
    "        node = Node(node_type, name=name)\n",
    "        node.__primarylabel__ = node_type\n",
    "        node.__primarykey__ = \"name\"\n",
    "        \n",
    "        tx.create(node)\n",
    "        \n",
    "tx.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####\n",
      "Alibaba\n",
      "(_0:Company {Type: 'Public', employee_num: 101958.0, employees: '101,958 (March 31, 2019)', founded: '4 April 1999 ; 20 years ago (1999-04-04) Hangzhou, Zhejiang', founded_yr: 1999, industry: 'Conglomerate', name: 'Alibaba', organization_name: 'Alibaba Group Holding Limited', products: 'E-commerce, Cloud computing, Entertainment, Mobile commerce, Retail, Mobile media, Films, TV shows', revenue: 'US$56.152 billion (2019)', revenue_num: 56152000000.0, services: 'Alibaba.com, Alibaba Cloud, AliExpress, AliOS, Alipay, AliGenie, Taobao, Tmall', website: 'AlibabaGroup.com'})\n",
      "#####\n",
      "Alibaba\n",
      "(_0:Company {Type: 'Public', employee_num: 101958.0, employees: '101,958 (March 31, 2019)', founded: '4 April 1999 ; 20 years ago (1999-04-04) Hangzhou, Zhejiang', founded_yr: 1999, industry: 'Conglomerate', name: 'Alibaba', organization_name: 'Alibaba Group Holding Limited', products: 'E-commerce, Cloud computing, Entertainment, Mobile commerce, Retail, Mobile media, Films, TV shows', revenue: 'US$56.152 billion (2019)', revenue_num: 56152000000.0, services: 'Alibaba.com, Alibaba Cloud, AliExpress, AliOS, Alipay, AliGenie, Taobao, Tmall', website: 'AlibabaGroup.com'})\n",
      "#####\n",
      "Alibaba\n",
      "(_0:Company {Type: 'Public', employee_num: 101958.0, employees: '101,958 (March 31, 2019)', founded: '4 April 1999 ; 20 years ago (1999-04-04) Hangzhou, Zhejiang', founded_yr: 1999, industry: 'Conglomerate', name: 'Alibaba', organization_name: 'Alibaba Group Holding Limited', products: 'E-commerce, Cloud computing, Entertainment, Mobile commerce, Retail, Mobile media, Films, TV shows', revenue: 'US$56.152 billion (2019)', revenue_num: 56152000000.0, services: 'Alibaba.com, Alibaba Cloud, AliExpress, AliOS, Alipay, AliGenie, Taobao, Tmall', website: 'AlibabaGroup.com'})\n",
      "#####\n",
      "Lazda Group\n",
      "(_185:Company {name: 'Lazda Group'})\n",
      "#####\n",
      "Alibaba\n",
      "(_0:Company {Type: 'Public', employee_num: 101958.0, employees: '101,958 (March 31, 2019)', founded: '4 April 1999 ; 20 years ago (1999-04-04) Hangzhou, Zhejiang', founded_yr: 1999, industry: 'Conglomerate', name: 'Alibaba', organization_name: 'Alibaba Group Holding Limited', products: 'E-commerce, Cloud computing, Entertainment, Mobile commerce, Retail, Mobile media, Films, TV shows', revenue: 'US$56.152 billion (2019)', revenue_num: 56152000000.0, services: 'Alibaba.com, Alibaba Cloud, AliExpress, AliOS, Alipay, AliGenie, Taobao, Tmall', website: 'AlibabaGroup.com'})\n",
      "#####\n",
      "Alibaba\n",
      "(_0:Company {Type: 'Public', employee_num: 101958.0, employees: '101,958 (March 31, 2019)', founded: '4 April 1999 ; 20 years ago (1999-04-04) Hangzhou, Zhejiang', founded_yr: 1999, industry: 'Conglomerate', name: 'Alibaba', organization_name: 'Alibaba Group Holding Limited', products: 'E-commerce, Cloud computing, Entertainment, Mobile commerce, Retail, Mobile media, Films, TV shows', revenue: 'US$56.152 billion (2019)', revenue_num: 56152000000.0, services: 'Alibaba.com, Alibaba Cloud, AliExpress, AliOS, Alipay, AliGenie, Taobao, Tmall', website: 'AlibabaGroup.com'})\n",
      "#####\n",
      "Ant Financial\n",
      "(_5:Company {employee_num: 9000.0, employees: '~9000', founded: 'October 16, 2014 ; 5 years ago (2014-10-16) in Hangzhou, Zhejiang, China', founded_yr: 2014, industry: 'Technology Financial services Payment processor', name: 'Ant Financial', organization_name: 'Ant Financial Services Group', products: 'Electronic payment processing Banking Mobile payment', website: 'www.antfinancial.com'})\n",
      "#####\n",
      "Ant Financial\n",
      "(_5:Company {employee_num: 9000.0, employees: '~9000', founded: 'October 16, 2014 ; 5 years ago (2014-10-16) in Hangzhou, Zhejiang, China', founded_yr: 2014, industry: 'Technology Financial services Payment processor', name: 'Ant Financial', organization_name: 'Ant Financial Services Group', products: 'Electronic payment processing Banking Mobile payment', website: 'www.antfinancial.com'})\n",
      "#####\n",
      "South China Morning Post\n",
      "(_8:Company {Type: 'Private', founded: '6 November 1903', founded_yr: 1903, founder: 'Tse Tsan-tai, Alfred Cunningham', industry: 'Newspaper publishing, Online media', name: 'South China Morning Post', organization_name: 'South China Morning Post', website: 'corp.scmp.com'})\n",
      "#####\n",
      "South China Morning Post\n",
      "(_8:Company {Type: 'Private', founded: '6 November 1903', founded_yr: 1903, founder: 'Tse Tsan-tai, Alfred Cunningham', industry: 'Newspaper publishing, Online media', name: 'South China Morning Post', organization_name: 'South China Morning Post', website: 'corp.scmp.com'})\n",
      "#####\n",
      "Alibaba\n",
      "(_0:Company {Type: 'Public', employee_num: 101958.0, employees: '101,958 (March 31, 2019)', founded: '4 April 1999 ; 20 years ago (1999-04-04) Hangzhou, Zhejiang', founded_yr: 1999, industry: 'Conglomerate', name: 'Alibaba', organization_name: 'Alibaba Group Holding Limited', products: 'E-commerce, Cloud computing, Entertainment, Mobile commerce, Retail, Mobile media, Films, TV shows', revenue: 'US$56.152 billion (2019)', revenue_num: 56152000000.0, services: 'Alibaba.com, Alibaba Cloud, AliExpress, AliOS, Alipay, AliGenie, Taobao, Tmall', website: 'AlibabaGroup.com'})\n",
      "#####\n",
      "Amazon\n",
      "(_1:Company {Type: 'Public', employee_num: 647500.0, employees: '647,500 (2018)', founded: 'July 5, 1994 ; 25 years ago (1994-07-05) in Bellevue, Washington, United States', founded_yr: 1994, industry: 'Cloud computing, E-commerce, Artificial intelligence, Consumer electronics, Digital distribution, Grocery stores', name: 'Amazon', organization_name: 'Amazon.com, Inc.', parent: 'none', products: 'Amazon Echo, Amazon Fire, Amazon Fire TV, Amazon Fire OS, Amazon Kindle', revenue: 'US$ 232.887 billion (2018)', revenue_num: 232887000000.0, services: 'Amazon.com, Amazon Alexa, Amazon Appstore, Amazon Music, Amazon Prime, Amazon Prime Video, Amazon Web Services', website: 'amazon.com(original U.S. site)'})\n",
      "#####\n",
      "eBay\n",
      "(_2:Company {Type: 'Public', employee_num: 14000.0, employees: '~14,000 (December 2018)', founded: 'September 3, 1995 ; 24 years ago (1995-09-03) (Originally as AuctionWeb)', founded_yr: 1995, industry: 'Internet', name: 'eBay', organization_name: 'eBay Inc.', revenue: 'US$ 10.746 billion (2018)', revenue_num: 10746000000.0, services: 'Online shopping', website: 'www.ebay.com'})\n",
      "#####\n",
      "Walmart\n",
      "(_3:Company {DESC: \"an American multinational retail corporation, world's largest company by revenue\", Headquarter: 'Bentonville, Arkansas', Number_of_Stores: '6080', Type: 'Public', employee_num: 2200000.0, employees: '2.2 million, Worldwide (2018) , 1.5 million, U.S. (2017) , 700,000, International', founded: 'June 13, 1945 ; 74 years ago (1945-06-13) (in Rogers, Arkansas)', founded_yr: 1945, industry: 'Retail', name: 'Walmart', organization_name: 'Walmart Inc.', products: 'Electronics, Movies and music, Home and furniture, Home improvement, Clothing, Footwear, Jewelry, Toys, Video games, Health and beauty, Pet supplies, Sporting goods and fitness, Auto, Photo finishing, Craft supplies, Baby products, Party supplies, Grocery', revenue: 'US$ 514.405 billion (2019)', revenue_num: 514405000000.0, services: 'Walmart-2-Walmart, Walmart MoneyCard, Pickup Today, Walmart.com, Financial Services, Walmart Pay', website: 'walmart.com'})\n",
      "#####\n",
      "Alibaba Pictures\n",
      "(_4:Company {industry: 'Film', name: 'Alibaba Pictures', organization_name: 'Alibaba Pictures', parent: 'Alibaba Group', website: 'www.alibabapictures.com'})\n",
      "#####\n",
      "Ant Financial\n",
      "(_5:Company {employee_num: 9000.0, employees: '~9000', founded: 'October 16, 2014 ; 5 years ago (2014-10-16) in Hangzhou, Zhejiang, China', founded_yr: 2014, industry: 'Technology Financial services Payment processor', name: 'Ant Financial', organization_name: 'Ant Financial Services Group', products: 'Electronic payment processing Banking Mobile payment', website: 'www.antfinancial.com'})\n",
      "#####\n",
      "Amblin Partners\n",
      "(_6:Company {Type: 'Joint venture', founded: 'December 16, 2015 ; 3 years ago (2015-12-16)', founded_yr: 2015, industry: 'Entertainment', name: 'Amblin Partners', organization_name: 'Storyteller Distribution Co., LLC', products: 'Motion pictures Television', website: 'amblin.com'})\n",
      "#####\n",
      "Vendio\n",
      "(_7:Company {founded: '1999', founded_yr: 1999, founder: 'Rodrigo Sales', industry: 'On-demand software', name: 'Vendio', organization_name: 'Vendio Services, Inc.', products: 'Vendio.com Dealio.com', website: 'Vendio.com'})\n",
      "#####\n",
      "South China Morning Post\n",
      "(_8:Company {Type: 'Private', founded: '6 November 1903', founded_yr: 1903, founder: 'Tse Tsan-tai, Alfred Cunningham', industry: 'Newspaper publishing, Online media', name: 'South China Morning Post', organization_name: 'South China Morning Post', website: 'corp.scmp.com'})\n",
      "#####\n",
      "Vudu\n",
      "(_20:Company {Avalable_via: 'PlayStation 3, PlayStation 4, Xbox 360, Vudu app, Android TV, Apple TV', DESC: 'an American content delivery and media technology company', Headquarter: 'Sunnyvale, California', Type: 'Subsidiary', founded: '2004', founded_yr: 2004, industry: 'P2P /TV', name: 'Vudu', organization_name: 'Vudu, Inc.', parent: 'Walmart (2010\\u2013present)', services: 'Video content delivery', website: 'www.vudu.com'})\n",
      "#####\n",
      "Jet.com\n",
      "(_21:Company {Headquarter: 'Hoboken, New Jersey', LunchWebsite: 'July,2015', MembershipFee: '$50 annual', employee_num: 5000.0, founded: 'April 2014 ; 5 years ago (2014-04)', founded_yr: 2014, founder: 'Marc Lore Nate Faust Mike Hanrahan', industry: 'Online shopping', name: 'Jet.com', organization_name: 'Jet.com', parent: 'Walmart', website: 'jet.com'})\n",
      "#####\n",
      "Shoes.com\n",
      "(_22:Company {Headquarter: 'Boston, Massachusetts', Previous: 'Shoebuy.com', Type: 'Subsidiary', employee_num: 200.0, employees: '200+ (2017)', founded: '1999', founded_yr: 1999, industry: 'E-commerce', name: 'Shoes.com', organization_name: 'Shoes.com', parent: 'Jet.com (2016-present)', products: 'Footwear (shoes, boots, slippers, sandals)', website: 'shoes.com'})\n",
      "#####\n",
      "Ring Inc.\n",
      "(_23:Company {Type: 'Subsidiary', employee_num: 1300.0, employees: '1,300 (2018)', founded: '2013 ; 6 years ago (2013) (as Doorbot)', founded_yr: 2013, name: 'Ring Inc.', organization_name: 'Ring Inc.', products: 'Smart doorbells Outdoor cameras Home alarm systems', services: 'Cloud recording Alarm monitoring', website: 'ring.com/'})\n",
      "#####\n",
      "Zappos\n",
      "(_24:Company {Type: 'Subsidiary', employee_num: 1500.0, employees: '1,500+', founded: 'July 12, 1999 ; 20 years ago (1999-07-12)', founded_yr: 1999, industry: 'Retail', name: 'Zappos', organization_name: 'Zappos.com', parent: 'Amazon', products: 'Shoes, handbags, eyewear, accessories, clothing', revenue: 'US$2 billion (2015)', revenue_num: 2000000000.0, website: 'zappos.com'})\n",
      "#####\n",
      "Whole Foods Market\n",
      "(_25:Company {Type: 'joint-stock company', employee_num: 91000.0, employees: '91,000', founded: 'June 2015 ; 4 years ago (2015-06)', founded_yr: 2015, industry: 'Retail groceries', name: 'Whole Foods Market', organization_name: 'Whole Foods Market, Inc.', parent: 'Whole Foods Market', website: '365bywfm.com'})\n",
      "#####\n",
      "PayPal\n",
      "(_26:Company {employee_num: 21800.0, founded: 'December 1998 ; 20 years ago (1998-12) (as Confinity) November 1999 ; 20 years ago (1999-11) (as X.com)', founded_yr: 1998, founder: 'Elon Musk, Ken Howery, Luke Nosek, Max Levchin, Peter Thiel, Yu Pan, Russel Simmons', industry: 'Financial services', name: 'PayPal', organization_name: 'PayPal Holdings Inc.', parent: 'eBay (2002\\u20132015)', products: 'Credit cards, payment systems', revenue: 'US$ 15.451 billion (2018)', revenue_num: 15451000000.0, website: 'www.paypal.com'})\n",
      "#####\n",
      "Skype Technologies\n",
      "(_27:Company {Type: 'Subsidiary', employee_num: 500.0, employees: '500 (2010)', founded: '2003 ; 16 years ago (2003)', founded_yr: 2003, industry: 'Telecommunications', name: 'Skype Technologies', organization_name: 'Skype Technologies S.A.R.L', parent: 'Microsoft', products: 'Skype, VoIP, IM, and video chat client for multiple platforms', revenue: 'US$ 2 billion (2013)', revenue_num: 2000000000.0, website: 'skype.com'})\n",
      "#####\n",
      "Craigslist\n",
      "(_28:Company {employee_num: 50.0, founded: '1995 (1995) (incorporated 1999)', founded_yr: 1995, founder: 'Craig Newmark', name: 'Craigslist', organization_name: 'Craigslist Inc.', revenue: 'US$ 694 million (2016)', revenue_num: 694000000.0, services: 'Web communications', website: 'www.craigslist.org'})\n",
      "#####\n",
      "Diapers.com\n",
      "(_112:Company {name: 'Diapers.com'})\n",
      "#####\n",
      "Moosejaw\n",
      "(_184:Company {name: 'Moosejaw'})\n",
      "#####\n",
      "Lazda Group\n",
      "(_185:Company {name: 'Lazda Group'})\n",
      "#####\n",
      "Alibaba Entrepreneurs Fund\n",
      "(_186:Company {name: 'Alibaba Entrepreneurs Fund'})\n",
      "#####\n",
      "Tencent\n",
      "(_190:Company {name: 'Tencent'})\n",
      "#####\n",
      "LLC\n",
      "(_191:Company {name: 'LLC'})\n",
      "#####\n",
      "Dreamworks Pictures\n",
      "(_192:Company {name: 'Dreamworks Pictures'})\n",
      "#####\n",
      "Ant Fortune\n",
      "(_194:Company {name: 'Ant Fortune'})\n",
      "#####\n",
      "Huabei\n",
      "(_195:Company {name: 'Huabei'})\n",
      "#####\n",
      "CK Hutchison Holdings\n",
      "(_196:Company {name: 'CK Hutchison Holdings'})\n",
      "#####\n",
      "HK Magazine\n",
      "(_198:Company {name: 'HK Magazine'})\n",
      "#####\n",
      "Taobao Marketplace\n",
      "(_200:Company {name: 'Taobao Marketplace'})\n",
      "#####\n",
      "EyeVerify Inc\n",
      "(_201:Company {name: 'EyeVerify Inc'})\n"
     ]
    }
   ],
   "source": [
    "# add node attributes\n",
    "g = Graph(host=HOST,user=USER,password=PW)\n",
    "tx = g.begin()\n",
    "\n",
    "matcher = NodeMatcher(g)\n",
    "\n",
    "with open('./clean_nlp/node_property.csv','rt')as f:\n",
    "    node_property = csv.reader(f)\n",
    "    for row in node_property:\n",
    "        \n",
    "        node = matcher.match(row[0],name=row[1]).first()\n",
    "        \n",
    "        key = row[2]\n",
    "        value = row[3]\n",
    "        \n",
    "        # ignore nodes that have already have the specific key within them\n",
    "        if key in node:\n",
    "            continue\n",
    "        \n",
    "        tx.merge(node)\n",
    "        node[key] = value\n",
    "        tx.push(node)\n",
    "                \n",
    "tx.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add node relationships\n",
    "g = Graph(host=HOST,user=USER,password=PW)\n",
    "tx = g.begin()\n",
    "\n",
    "matcher = NodeMatcher(g)\n",
    "\n",
    "with open('./clean_nlp/node_connectivity.json', 'r') as f:\n",
    "    node_c = json.load(f)\n",
    "        \n",
    "for j in node_c:\n",
    "    \n",
    "    for k in j['Node1'].keys():\n",
    "        label1 = k\n",
    "    for k in j['Node2'].keys():\n",
    "        label2 = k\n",
    "        \n",
    "    node1 = matcher.match(label1,name=j['Node1'][label1]).first()\n",
    "    node2 = matcher.match(label2,name=j['Node2'][label2]).first()\n",
    "    \n",
    "    r = Relationship(node1, j['Edge']['Label'], node2)\n",
    "    for k in j['Edge']:\n",
    "        if k == 'Label':\n",
    "            continue\n",
    "        else:\n",
    "            r[k] = j['Edge'][k]\n",
    "            \n",
    "    tx.create(r)\n",
    "\n",
    "tx.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## just going to add location to all of the company fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
